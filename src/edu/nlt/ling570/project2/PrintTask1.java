package edu.nlt.ling570.project2;

import java.io.File;
import java.util.Collection;

import edu.nlt.ling570.project2.data.ClassifierGoldStandard;
import edu.nlt.ling570.project2.data.FileClassifierAdapter;
import edu.nlt.ling570.project2.data.LinguisticCluster;
import edu.nlt.shallow.classifier.BinaryFileClassifier;
import edu.nlt.shallow.classifier.NotClassifiedException;
import edu.nlt.shallow.data.Vocabulary;
import edu.nlt.shallow.data.vector.DocumentVector;
import edu.nlt.util.FileProcessor;
import edu.nlt.util.Formatters;
import edu.nlt.util.Globals;
import edu.nlt.util.InputUtil;
import edu.nlt.util.MathUtil;

public class PrintTask1 {
	/**
	 * Classifies standard input as Linguistic / Non-linguistic
	 * 
	 * @param args
	 * 
	 * 
	 *            args[0] - Vocabulary file
	 * 
	 *            args[1] - Cluster centroids file (generated by PrintClusters
	 *            program)
	 * 
	 *            args[2] - Tags - gold standard
	 * 
	 *            args[3] - Path to untagged documents
	 */
	public static void main(String[] args) {

		final Vocabulary vocabulary = Util.getVocabulary(new File(args[0]), -1);
		final Collection<LinguisticCluster> clusters = Util.getClusters(new File(args[1]),
				vocabulary);
		final ClassifierGoldStandard goldStandard = Util.getGoldStandard(new File(args[2]));

		TestProcessor processor = new TestProcessor(vocabulary, clusters,
				new FileClassifierAdapter(goldStandard));
		InputUtil.processFiles(args[3], processor);
		processor.printPrescisionRecall();
	}
}

class TestProcessor implements FileProcessor {

	private Collection<LinguisticCluster> clusters;

	private BinaryFileClassifier goldStandard;

	private Vocabulary vocabulary;

	private int truePositives;
	private int relevantDocuments;
	private int documentsRetrieved;

	public TestProcessor(Vocabulary vocabulary, Collection<LinguisticCluster> clusters,
			BinaryFileClassifier goldStandard) {
		super();

		this.vocabulary = vocabulary;
		this.clusters = clusters;
		this.goldStandard = goldStandard;
	}

	@Override
	public void processFile(File file) {
		DocumentVector document = Util.getDocumentVector(file, vocabulary);

		boolean isLinguistic = Classify.isPositive(clusters, document);

		System.out.println(ClassifierGoldStandard.canonizeName(file.getName())
				+ (isLinguistic ? "\tX" : ""));

		boolean isLinguisticGold = false;
		try {
			isLinguisticGold = goldStandard.isPositive(file);
		} catch (NotClassifiedException e) {
			e.printStackTrace(System.err);
		}

		if (isLinguisticGold) {
			relevantDocuments++;
		}

		if (isLinguistic) {
			documentsRetrieved++;
			if (isLinguisticGold) {
				truePositives++;

			}
		}

		if (Globals.IsDebugEnabled) {
			if (isLinguistic && !isLinguisticGold) {
				System.err.println("False positive:\t" + file.getName());
			}

			else if (!isLinguistic && isLinguisticGold) {
				System.err.println("False negative :\t" + file.getName());
			}
		}

	}

	public void printPrescisionRecall() {
		System.out.println();
		double precision = (double) truePositives / (double) documentsRetrieved;
		double recall = (double) truePositives / (double) relevantDocuments;

		System.out.println("Precision\t" + Formatters.PercentageFormatter.format(precision));
		System.out.println("Recall:\t\t" + Formatters.PercentageFormatter.format(recall));

		double fScore = MathUtil.getFScore(truePositives, documentsRetrieved, relevantDocuments);
		System.out.println("F-measure:\t" + Formatters.PercentageFormatter.format(fScore));
	}
}
