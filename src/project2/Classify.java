package project2;

import java.io.File;
import java.util.Collection;

import project2.data.LinguisticCluster;
import project2.data.Vocabulary;
import project2.processor.DocumentVectorProcessor;
import project2.processor.PlainWordProcessor;
import edu.nlt.shallow.data.vector.DocumentVector;
import edu.nlt.util.InputUtil;

public class Classify {

	/**
	 * Classifies standard input as Linguistic / Non-linguistic
	 * 
	 * @param args
	 * 
	 * 
	 *            args[0] - Vocabulary file
	 * 
	 *            args[1] - Cluster centroids file (generated by PrintClusters
	 *            program)
	 * 
	 * 
	 */
	public static void main(String[] args) {

		Vocabulary vocabulary = Util.getVocabulary(new File(args[0]), -1);
		Collection<LinguisticCluster> clusters = Util.getClusters(new File(args[1]), vocabulary);

		// Create document vector for input
		//
		DocumentVector document;
		{
			DocumentVectorProcessor processor = new DocumentVectorProcessor(vocabulary,
					"Standard input");
			InputUtil.process(System.in, new PlainWordProcessor(processor));
			document = processor.getDocumentVector();
		}

		System.out.println(isLinguistic(clusters, document) ? "Linguistic" : "Non-linguistic");
	}

	public static boolean isLinguistic(Collection<LinguisticCluster> clusters,
			DocumentVector document) {
		double maxSimiliraty = Double.MIN_VALUE;
		boolean isLinguistic = false;

		for (LinguisticCluster cluster : clusters) {

			double similarity = cluster.getCosineSimilarity(document);
			if (similarity > maxSimiliraty) {
				maxSimiliraty = similarity;
				isLinguistic = cluster.isLinguistic();

			}

		}

		return isLinguistic;

	}
}
