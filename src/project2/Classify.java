package project2;

import java.io.File;
import java.util.HashSet;
import java.util.List;

import project2.data.LinguisticCluster;
import project2.processor.ClustersProcessor;
import project2.processor.DocumentVectorProcessor;
import project2.processor.PlainWordProcessor;
import edu.nlt.shallow.data.table.IDFTable;
import edu.nlt.shallow.data.vector.DocumentVector;
import edu.nlt.util.InputUtil;

public class Classify {

	/**
	 * Classifies standard input as Linguistic / Non-linguistic
	 * 
	 * @param args
	 * 
	 * 
	 *            args[0] - Vocabulary file
	 * 
	 *            args[1] - IDFTable file
	 * 
	 *            args[2] Cluster centroids file (generated by PrintClusters
	 *            program)
	 */
	public static void main(String[] args) {

		IDFTable idfTable = Util.getIDFTable(new File(args[0]));
		HashSet<String> vocabulary = Util.getVocabulary(new File(args[1]));

		// Re-construct linguistic clusters
		List<LinguisticCluster> clusters;
		{
			ClustersProcessor processor = new ClustersProcessor(vocabulary);
			InputUtil.process(new File(args[2]), processor);

			clusters = processor.getVectors();
		}

		// Create document vector for input
		//
		DocumentVector vector;
		{
			DocumentVectorProcessor processor = new DocumentVectorProcessor(idfTable, vocabulary);
			InputUtil.process(System.in, new PlainWordProcessor(processor));
			vector = processor.getDocumentVector();
		}

		double maxSimiliraty = Double.MIN_VALUE;
		boolean isLinguistic = false;

		for (LinguisticCluster cluster : clusters) {

			double similarity = cluster.getCosineSimilarity(vector);
			if (similarity > maxSimiliraty) {
				maxSimiliraty = similarity;
				isLinguistic = cluster.isLinguistic();

			}

		}

		System.out.println(isLinguistic ? "Linguistic" : "Non-linguistic");
	}
}
