package project2;

import java.io.File;
import java.util.Collection;
import java.util.HashSet;

import project2.data.LinguisticCluster;
import project2.processor.GoldStandard;
import edu.nlt.shallow.data.table.IDFTable;
import edu.nlt.shallow.data.vector.DocumentVector;
import edu.nlt.util.FileProcessor;
import edu.nlt.util.InputUtil;
import edu.nlt.util.Singletons;

public class PrintTask1 {
	/**
	 * Classifies standard input as Linguistic / Non-linguistic
	 * 
	 * @param args
	 * 
	 * 
	 *            args[0] - Vocabulary file
	 * 
	 *            args[1] - IDFTable file
	 * 
	 *            args[2] - Cluster centroids file (generated by PrintClusters
	 *            program)
	 * 
	 *            args[3] - Tags - gold standard
	 * 
	 *            args[4] - Path to untagged documents
	 */
	public static void main(String[] args) {
		final IDFTable idfTable = Util.getIDFTable(new File(args[0]));
		final HashSet<String> vocabulary = Util.getVocabulary(new File(args[1]));
		final Collection<LinguisticCluster> clusters = Util.getClusters(new File(args[2]),
				vocabulary);
		final GoldStandard goldStandard = Util.getGoldStandard(new File(args[3]));

		TestProcessor processor = new TestProcessor(idfTable, vocabulary, clusters, goldStandard);
		InputUtil.processFiles(args[4], processor);
		processor.printPrescisionRecall();
	}
}

class TestProcessor implements FileProcessor {

	private Collection<LinguisticCluster> clusters;

	private GoldStandard goldStandard;
	private IDFTable idfTable;
	private HashSet<String> vocabulary;

	private int truePositives;
	private int relevantDocuments;
	private int documentsRetrieved;

	public TestProcessor(IDFTable idfTable, HashSet<String> vocabulary,
			Collection<LinguisticCluster> clusters, GoldStandard goldStandard) {
		super();
		this.idfTable = idfTable;
		this.vocabulary = vocabulary;
		this.clusters = clusters;
		this.goldStandard = goldStandard;
	}

	@Override
	public void processFile(File file) {
		DocumentVector document = Util.getDocumentVector(file, idfTable, vocabulary);

		boolean isLinguistic = Classify.isLinguistic(clusters, document);

		System.out.println(file.getName().split("\\.")[0] + (isLinguistic ? "\tX" : ""));

		boolean isLinguisticGold = goldStandard.isLinguistic(file.getName());

		if (isLinguisticGold) {
			relevantDocuments++;
		}

		if (isLinguistic) {
			documentsRetrieved++;
			if (isLinguisticGold) {
				truePositives++;

			}
		}

		if (isLinguistic && !isLinguisticGold) {
			System.out.println("False positive:\t" + file.getName());
		}

		else if (!isLinguistic && isLinguistic) {
			System.out.println("False negative :\t" + file.getName());
		}
	}

	public void printPrescisionRecall() {
		double precision = (double) truePositives / (double) documentsRetrieved;
		double recall = (double) truePositives / (double) relevantDocuments;

		System.out.println("Precision:t" + Singletons.FractionFormatter.format(precision));
		System.out.println("Recall:\t" + Singletons.FractionFormatter.format(recall));
	}
}
